{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importing modules and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05:34:24] Initializing Normalizer\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import AllChem, Descriptors\n",
    "from rdkit.ML.Descriptors import MoleculeDescriptors\n",
    "import chembl_structure_pipeline\n",
    "from molvs import standardize_smiles\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.model_selection import permutation_test_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import joblib\n",
    "import pickle\n",
    "from numpy import savetxt\n",
    "from padelpy import from_sdf\n",
    "from IPython.display import HTML\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Data entry and curation work set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data:  1400 molecules\n",
      "Failed data:  0 molecules\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No. failed molecule in original set</th>\n",
       "      <th>SMILES of wrong structure:</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No.</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [No. failed molecule in original set, SMILES of wrong structure: ]\n",
       "Index: []"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uploaded_file_ws=\"datasets/HDAC3_work.sdf\"\n",
    "supplier_ws = Chem.ForwardSDMolSupplier(uploaded_file_ws,sanitize=False)\n",
    "failed_mols_ws = []\n",
    "all_mols_ws =[]\n",
    "wrong_structure_ws=[]\n",
    "wrong_smiles_ws=[]\n",
    "y_tr = []\n",
    "y_bad_index=[]\n",
    "\n",
    "for i, m in enumerate(supplier_ws):\n",
    "    structure = Chem.Mol(m)\n",
    "    all_mols_ws.append(structure)\n",
    "    y_tr.append(m.GetProp(\"pchembl_value_mean\"))\n",
    "    try:\n",
    "        Chem.SanitizeMol(structure)\n",
    "    except:\n",
    "        failed_mols_ws.append(m)\n",
    "        wrong_smiles_ws.append(Chem.MolToSmiles(m))\n",
    "        wrong_structure_ws.append(str(i+1))\n",
    "        y_bad_index.append(i)\n",
    "print('Original data: ', len(all_mols_ws), 'molecules')\n",
    "print('Failed data: ', len(failed_mols_ws), 'molecules')\n",
    "number_ws =[]\n",
    "for i in range(len(failed_mols_ws)):\n",
    "        number_ws.append(str(i+1))\n",
    "bad_molecules_ws = pd.DataFrame({'No. failed molecule in original set': wrong_structure_ws, 'SMILES of wrong structure: ': wrong_smiles_ws, 'No.': number_ws}, index=None)\n",
    "bad_molecules_ws = bad_molecules_ws.set_index('No.')\n",
    "bad_molecules_ws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "deleting activity values for substances with incorrect structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr[:] = [x for i,x in enumerate(y_tr) if i not in y_bad_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1400"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Standardization SDF file for work set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kept data:  1400 molecules\n"
     ]
    }
   ],
   "source": [
    "all_mols_ws[:] = [x for i,x in enumerate(all_mols_ws) if i not in y_bad_index] \n",
    "records = []\n",
    "for i in range(len(all_mols_ws)):\n",
    "    record = Chem.MolToSmiles(all_mols_ws[i])\n",
    "    records.append(record)\n",
    "\n",
    "moldf_ws = []\n",
    "for i,record in enumerate(records):\n",
    "    standard_record = standardize_smiles(record)\n",
    "    m = Chem.MolFromSmiles(standard_record)\n",
    "    moldf_ws.append(m)\n",
    "    \n",
    "print('Kept data: ', len(moldf_ws), 'molecules')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x00000224172...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x00000224543...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x00000224172...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x00000224172...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x00000224172...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x00000224192...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x00000224192...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x00000224192...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x00000224192...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x00000224192...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1400 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Mol\n",
       "0     <rdkit.Chem.rdchem.Mol object at 0x00000224172...\n",
       "1     <rdkit.Chem.rdchem.Mol object at 0x00000224543...\n",
       "2     <rdkit.Chem.rdchem.Mol object at 0x00000224172...\n",
       "3     <rdkit.Chem.rdchem.Mol object at 0x00000224172...\n",
       "4     <rdkit.Chem.rdchem.Mol object at 0x00000224172...\n",
       "...                                                 ...\n",
       "1395  <rdkit.Chem.rdchem.Mol object at 0x00000224192...\n",
       "1396  <rdkit.Chem.rdchem.Mol object at 0x00000224192...\n",
       "1397  <rdkit.Chem.rdchem.Mol object at 0x00000224192...\n",
       "1398  <rdkit.Chem.rdchem.Mol object at 0x00000224192...\n",
       "1399  <rdkit.Chem.rdchem.Mol object at 0x00000224192...\n",
       "\n",
       "[1400 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moldf_ws=pd.DataFrame(moldf_ws, columns=['Mol'])\n",
    "moldf_ws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.Data entry and curation test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data:  351 molecules\n",
      "Failed data:  0 molecules\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No. failed molecule in original set</th>\n",
       "      <th>SMILES of wrong structure:</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No.</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [No. failed molecule in original set, SMILES of wrong structure: ]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uploaded_file_ts=\"datasets/HDAC3_test.sdf\"\n",
    "supplier_ts = Chem.ForwardSDMolSupplier(uploaded_file_ts,sanitize=False)\n",
    "failed_mols_ts = []\n",
    "all_mols_ts =[]\n",
    "wrong_structure_ts=[]\n",
    "wrong_smiles_ts=[]\n",
    "y_ts = []\n",
    "y_bad_index=[]\n",
    "for i, m in enumerate(supplier_ts):\n",
    "    structure = Chem.Mol(m)\n",
    "    all_mols_ts.append(structure)\n",
    "    y_ts.append(m.GetProp(\"pchembl_value_mean\"))\n",
    "    try:\n",
    "        Chem.SanitizeMol(structure)\n",
    "    except:\n",
    "        failed_mols_ts.append(m)\n",
    "        wrong_smiles_ts.append(Chem.MolToSmiles(m))\n",
    "        wrong_structure_ts.append(str(i+1))\n",
    "        y_bad_index.append(i)\n",
    "print('Original data: ', len(all_mols_ts), 'molecules')\n",
    "print('Failed data: ', len(failed_mols_ts), 'molecules')\n",
    "number_ts =[]\n",
    "for i in range(len(failed_mols_ts)):\n",
    "        number_ts.append(str(i+1))\n",
    "bad_molecules_ts = pd.DataFrame({'No. failed molecule in original set': wrong_structure_ts, 'SMILES of wrong structure: ': wrong_smiles_ts, 'No.': number_ts}, index=None)\n",
    "bad_molecules_ts = bad_molecules_ts.set_index('No.')\n",
    "bad_molecules_ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "deleting activity values for substances with incorrect structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ts[:] = [x for i,x in enumerate(y_ts) if i not in y_bad_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "351"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.Standardization SDF file for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kept data:  351 molecules\n"
     ]
    }
   ],
   "source": [
    "all_mols_ts[:] = [x for i,x in enumerate(all_mols_ts) if i not in y_bad_index] \n",
    "records = []\n",
    "for i in range(len(all_mols_ts)):\n",
    "    record = Chem.MolToSmiles(all_mols_ts[i])\n",
    "    records.append(record)\n",
    "\n",
    "moldf_ts = []\n",
    "for i,record in enumerate(records):\n",
    "    standard_record = standardize_smiles(record)\n",
    "    m = Chem.MolFromSmiles(standard_record)\n",
    "    moldf_ts.append(m)\n",
    "    \n",
    "print('Kept data: ', len(moldf_ts), 'molecules')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x00000224172...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x00000224172...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x00000224172...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x00000224172...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x00000224172...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x00000224172...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x00000224172...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x00000224172...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x00000224172...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x00000224172...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>351 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Mol\n",
       "0    <rdkit.Chem.rdchem.Mol object at 0x00000224172...\n",
       "1    <rdkit.Chem.rdchem.Mol object at 0x00000224172...\n",
       "2    <rdkit.Chem.rdchem.Mol object at 0x00000224172...\n",
       "3    <rdkit.Chem.rdchem.Mol object at 0x00000224172...\n",
       "4    <rdkit.Chem.rdchem.Mol object at 0x00000224172...\n",
       "..                                                 ...\n",
       "346  <rdkit.Chem.rdchem.Mol object at 0x00000224172...\n",
       "347  <rdkit.Chem.rdchem.Mol object at 0x00000224172...\n",
       "348  <rdkit.Chem.rdchem.Mol object at 0x00000224172...\n",
       "349  <rdkit.Chem.rdchem.Mol object at 0x00000224172...\n",
       "350  <rdkit.Chem.rdchem.Mol object at 0x00000224172...\n",
       "\n",
       "[351 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moldf_ts=pd.DataFrame(moldf_ts, columns=['Mol'])\n",
    "moldf_ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.Calculation MorganFingerprint for work set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bit_0</th>\n",
       "      <th>Bit_1</th>\n",
       "      <th>Bit_2</th>\n",
       "      <th>Bit_3</th>\n",
       "      <th>Bit_4</th>\n",
       "      <th>Bit_5</th>\n",
       "      <th>Bit_6</th>\n",
       "      <th>Bit_7</th>\n",
       "      <th>Bit_8</th>\n",
       "      <th>Bit_9</th>\n",
       "      <th>...</th>\n",
       "      <th>Bit_1014</th>\n",
       "      <th>Bit_1015</th>\n",
       "      <th>Bit_1016</th>\n",
       "      <th>Bit_1017</th>\n",
       "      <th>Bit_1018</th>\n",
       "      <th>Bit_1019</th>\n",
       "      <th>Bit_1020</th>\n",
       "      <th>Bit_1021</th>\n",
       "      <th>Bit_1022</th>\n",
       "      <th>Bit_1023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1400 rows Ã— 1024 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Bit_0  Bit_1  Bit_2  Bit_3  Bit_4  Bit_5  Bit_6  Bit_7  Bit_8  Bit_9  \\\n",
       "0         0      1      0      0      0      0      0      0      0      0   \n",
       "1         0      1      0      0      0      0      0      0      0      0   \n",
       "2         0      0      0      0      0      0      0      0      1      0   \n",
       "3         0      0      0      0      0      0      0      0      0      0   \n",
       "4         0      0      0      0      0      0      0      0      1      0   \n",
       "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "1395      0      1      0      0      0      0      0      0      0      0   \n",
       "1396      0      1      0      0      0      0      0      0      0      0   \n",
       "1397      0      1      0      0      0      0      0      0      0      0   \n",
       "1398      0      1      0      0      1      0      0      0      1      0   \n",
       "1399      0      1      0      0      0      0      0      0      0      0   \n",
       "\n",
       "      ...  Bit_1014  Bit_1015  Bit_1016  Bit_1017  Bit_1018  Bit_1019  \\\n",
       "0     ...         0         0         0         0         0         0   \n",
       "1     ...         0         0         0         0         0         0   \n",
       "2     ...         0         0         0         0         0         0   \n",
       "3     ...         0         0         0         0         0         0   \n",
       "4     ...         0         0         0         0         0         0   \n",
       "...   ...       ...       ...       ...       ...       ...       ...   \n",
       "1395  ...         0         0         1         0         0         1   \n",
       "1396  ...         0         0         1         0         0         1   \n",
       "1397  ...         0         0         1         0         0         1   \n",
       "1398  ...         0         0         0         0         0         1   \n",
       "1399  ...         0         0         1         0         0         1   \n",
       "\n",
       "      Bit_1020  Bit_1021  Bit_1022  Bit_1023  \n",
       "0            0         0         0         0  \n",
       "1            0         0         0         0  \n",
       "2            0         0         0         0  \n",
       "3            0         0         0         0  \n",
       "4            0         0         0         0  \n",
       "...        ...       ...       ...       ...  \n",
       "1395         0         0         0         0  \n",
       "1396         0         0         0         0  \n",
       "1397         0         0         0         0  \n",
       "1398         0         0         0         0  \n",
       "1399         0         0         0         0  \n",
       "\n",
       "[1400 rows x 1024 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calcfp(mol,funcFPInfo=dict(radius=2, nBits=1024, useFeatures=False, useChirality=False)):\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, **funcFPInfo)\n",
    "    fp = pd.Series(np.asarray(fp))\n",
    "    fp = fp.add_prefix('Bit_')\n",
    "    return fp\n",
    "\n",
    "# Training set\n",
    "desc_ws = moldf_ws.Mol.apply(calcfp)\n",
    "desc_ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1400"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr = np.array(y_tr, dtype=np.float32)\n",
    "len(y_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.Calculation MorganFingerprint for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bit_0</th>\n",
       "      <th>Bit_1</th>\n",
       "      <th>Bit_2</th>\n",
       "      <th>Bit_3</th>\n",
       "      <th>Bit_4</th>\n",
       "      <th>Bit_5</th>\n",
       "      <th>Bit_6</th>\n",
       "      <th>Bit_7</th>\n",
       "      <th>Bit_8</th>\n",
       "      <th>Bit_9</th>\n",
       "      <th>...</th>\n",
       "      <th>Bit_1014</th>\n",
       "      <th>Bit_1015</th>\n",
       "      <th>Bit_1016</th>\n",
       "      <th>Bit_1017</th>\n",
       "      <th>Bit_1018</th>\n",
       "      <th>Bit_1019</th>\n",
       "      <th>Bit_1020</th>\n",
       "      <th>Bit_1021</th>\n",
       "      <th>Bit_1022</th>\n",
       "      <th>Bit_1023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>351 rows Ã— 1024 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Bit_0  Bit_1  Bit_2  Bit_3  Bit_4  Bit_5  Bit_6  Bit_7  Bit_8  Bit_9  \\\n",
       "0        0      1      0      0      0      0      0      0      0      0   \n",
       "1        0      0      0      0      0      0      0      0      0      0   \n",
       "2        0      0      0      0      0      0      0      0      0      0   \n",
       "3        0      1      0      0      0      0      0      0      0      0   \n",
       "4        0      0      0      0      1      0      0      0      0      0   \n",
       "..     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "346      0      1      0      0      0      0      0      0      0      0   \n",
       "347      0      1      0      0      0      0      0      0      0      0   \n",
       "348      0      1      0      0      0      0      0      0      0      0   \n",
       "349      0      0      1      0      1      0      0      0      0      0   \n",
       "350      0      0      1      0      1      0      0      0      0      0   \n",
       "\n",
       "     ...  Bit_1014  Bit_1015  Bit_1016  Bit_1017  Bit_1018  Bit_1019  \\\n",
       "0    ...         0         0         0         0         0         0   \n",
       "1    ...         0         0         0         0         0         0   \n",
       "2    ...         0         0         0         0         0         1   \n",
       "3    ...         0         0         0         0         0         0   \n",
       "4    ...         0         0         0         0         0         0   \n",
       "..   ...       ...       ...       ...       ...       ...       ...   \n",
       "346  ...         0         0         1         0         0         1   \n",
       "347  ...         0         0         1         0         0         1   \n",
       "348  ...         0         0         1         0         0         1   \n",
       "349  ...         0         0         1         0         0         1   \n",
       "350  ...         0         0         1         0         0         1   \n",
       "\n",
       "     Bit_1020  Bit_1021  Bit_1022  Bit_1023  \n",
       "0           0         0         0         0  \n",
       "1           0         0         0         0  \n",
       "2           0         0         0         0  \n",
       "3           0         0         0         0  \n",
       "4           1         0         0         0  \n",
       "..        ...       ...       ...       ...  \n",
       "346         0         0         0         0  \n",
       "347         0         0         0         0  \n",
       "348         0         0         0         0  \n",
       "349         0         0         0         0  \n",
       "350         0         0         0         0  \n",
       "\n",
       "[351 rows x 1024 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc_ts = moldf_ts.Mol.apply(calcfp)\n",
    "desc_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ts = np.array(y_ts, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BASELINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## GradientBoostingRegressor model building and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=KFold(n_splits=5, random_state=seed, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = GradientBoostingRegressor(learning_rate=0.01,subsample= 0.5, n_estimators=1000, max_depth= 10,  random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor(learning_rate=0.01, max_depth=10, n_estimators=1000,\n",
       "                          random_state=42, subsample=0.5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(learning_rate=0.01, max_depth=10, n_estimators=1000,\n",
       "                          random_state=42, subsample=0.5)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingRegressor(learning_rate=0.01, max_depth=10, n_estimators=1000,\n",
       "                          random_state=42, subsample=0.5)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.fit(desc_ws, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_CV_GBR = cross_val_predict(estimator, desc_ws, y_tr, cv=cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q2_CV = round(r2_score(y_tr, y_pred_CV_GBR), 2)\n",
    "Q2_CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE_CV=round(np.sqrt(mean_squared_error(y_tr, y_pred_CV_GBR)), 2)\n",
    "RMSE_CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance_threshold_selector(data, threshold=0.5):\n",
    "    selector = VarianceThreshold(threshold)\n",
    "    selector.fit(data)\n",
    "    return data[data.columns[selector.get_support(indices=True)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bit_1</th>\n",
       "      <th>Bit_4</th>\n",
       "      <th>Bit_8</th>\n",
       "      <th>Bit_14</th>\n",
       "      <th>Bit_15</th>\n",
       "      <th>Bit_25</th>\n",
       "      <th>Bit_31</th>\n",
       "      <th>Bit_33</th>\n",
       "      <th>Bit_36</th>\n",
       "      <th>Bit_41</th>\n",
       "      <th>...</th>\n",
       "      <th>Bit_967</th>\n",
       "      <th>Bit_971</th>\n",
       "      <th>Bit_980</th>\n",
       "      <th>Bit_997</th>\n",
       "      <th>Bit_999</th>\n",
       "      <th>Bit_1009</th>\n",
       "      <th>Bit_1010</th>\n",
       "      <th>Bit_1016</th>\n",
       "      <th>Bit_1017</th>\n",
       "      <th>Bit_1019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1400 rows Ã— 209 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Bit_1  Bit_4  Bit_8  Bit_14  Bit_15  Bit_25  Bit_31  Bit_33  Bit_36  \\\n",
       "0         1      0      0       0       0       0       0       1       0   \n",
       "1         1      0      0       0       0       0       0       0       0   \n",
       "2         0      0      1       0       1       0       0       1       0   \n",
       "3         0      0      0       0       1       0       0       1       0   \n",
       "4         0      0      1       0       0       0       0       1       0   \n",
       "...     ...    ...    ...     ...     ...     ...     ...     ...     ...   \n",
       "1395      1      0      0       0       0       0       0       1       1   \n",
       "1396      1      0      0       0       0       0       0       1       1   \n",
       "1397      1      0      0       0       0       0       0       1       1   \n",
       "1398      1      1      1       0       0       0       0       1       0   \n",
       "1399      1      0      0       0       0       0       0       1       1   \n",
       "\n",
       "      Bit_41  ...  Bit_967  Bit_971  Bit_980  Bit_997  Bit_999  Bit_1009  \\\n",
       "0          1  ...        0        0        0        0        0         0   \n",
       "1          1  ...        0        0        0        0        0         0   \n",
       "2          0  ...        0        0        0        0        0         0   \n",
       "3          1  ...        0        0        0        0        0         0   \n",
       "4          0  ...        0        0        0        0        0         0   \n",
       "...      ...  ...      ...      ...      ...      ...      ...       ...   \n",
       "1395       0  ...        0        1        0        1        0         0   \n",
       "1396       0  ...        0        1        0        1        0         0   \n",
       "1397       0  ...        0        1        0        1        0         0   \n",
       "1398       0  ...        0        1        0        0        0         0   \n",
       "1399       0  ...        0        0        0        1        0         0   \n",
       "\n",
       "      Bit_1010  Bit_1016  Bit_1017  Bit_1019  \n",
       "0            0         0         0         0  \n",
       "1            0         0         0         0  \n",
       "2            0         0         0         0  \n",
       "3            0         0         0         0  \n",
       "4            0         0         0         0  \n",
       "...        ...       ...       ...       ...  \n",
       "1395         1         1         0         1  \n",
       "1396         1         1         0         1  \n",
       "1397         1         1         0         1  \n",
       "1398         0         0         0         1  \n",
       "1399         1         1         0         1  \n",
       "\n",
       "[1400 rows x 209 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tr_const_and_nearcont=variance_threshold_selector(desc_ws, 0.05)\n",
    "x_tr_const_and_nearcont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor(learning_rate=0.01, max_depth=10, n_estimators=1000,\n",
       "                          random_state=42, subsample=0.5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(learning_rate=0.01, max_depth=10, n_estimators=1000,\n",
       "                          random_state=42, subsample=0.5)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingRegressor(learning_rate=0.01, max_depth=10, n_estimators=1000,\n",
       "                          random_state=42, subsample=0.5)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.fit(x_tr_const_and_nearcont, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_CV_GBR = cross_val_predict(estimator, x_tr_const_and_nearcont, y_tr, cv=cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q2_CV = round(r2_score(y_tr, y_pred_CV_GBR), 2)\n",
    "Q2_CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE_CV=round(np.sqrt(mean_squared_error(y_tr, y_pred_CV_GBR)), 2)\n",
    "RMSE_CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding and removing duplicate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_duplicates(X):\n",
    "    pairs = {}\n",
    "    dups = []\n",
    "    for i in range(X.shape[1]):\n",
    "        feat_outer = X.columns[i]\n",
    "        if feat_outer not in dups:\n",
    "           for feat_inner in X.columns[i + 1:]:\n",
    "                if X[feat_outer].equals(X[feat_inner]):\n",
    "                    pairs[feat_outer].append(feat_inner)\n",
    "                    dups.append(feat_inner)\n",
    "    result={}\n",
    "    for key in  pairs:\n",
    "        if len(pairs[key])>0:\n",
    "            result[key]=pairs[key]     \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_duplicates(x_tr_const_and_nearcont)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing highly correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bit_1</th>\n",
       "      <th>Bit_4</th>\n",
       "      <th>Bit_8</th>\n",
       "      <th>Bit_14</th>\n",
       "      <th>Bit_15</th>\n",
       "      <th>Bit_25</th>\n",
       "      <th>Bit_31</th>\n",
       "      <th>Bit_33</th>\n",
       "      <th>Bit_36</th>\n",
       "      <th>Bit_41</th>\n",
       "      <th>...</th>\n",
       "      <th>Bit_967</th>\n",
       "      <th>Bit_971</th>\n",
       "      <th>Bit_980</th>\n",
       "      <th>Bit_997</th>\n",
       "      <th>Bit_999</th>\n",
       "      <th>Bit_1009</th>\n",
       "      <th>Bit_1010</th>\n",
       "      <th>Bit_1016</th>\n",
       "      <th>Bit_1017</th>\n",
       "      <th>Bit_1019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bit_1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.023343</td>\n",
       "      <td>0.060250</td>\n",
       "      <td>0.009891</td>\n",
       "      <td>0.011247</td>\n",
       "      <td>0.051526</td>\n",
       "      <td>0.056199</td>\n",
       "      <td>0.309418</td>\n",
       "      <td>0.204014</td>\n",
       "      <td>0.181086</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111018</td>\n",
       "      <td>0.466243</td>\n",
       "      <td>0.044719</td>\n",
       "      <td>0.087555</td>\n",
       "      <td>0.194876</td>\n",
       "      <td>0.077911</td>\n",
       "      <td>0.311692</td>\n",
       "      <td>0.403763</td>\n",
       "      <td>0.021016</td>\n",
       "      <td>0.351924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bit_4</th>\n",
       "      <td>0.023343</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027675</td>\n",
       "      <td>0.014926</td>\n",
       "      <td>0.037057</td>\n",
       "      <td>0.026979</td>\n",
       "      <td>0.016688</td>\n",
       "      <td>0.129453</td>\n",
       "      <td>0.123931</td>\n",
       "      <td>0.068172</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079457</td>\n",
       "      <td>0.007767</td>\n",
       "      <td>0.014474</td>\n",
       "      <td>0.081022</td>\n",
       "      <td>0.017261</td>\n",
       "      <td>0.042160</td>\n",
       "      <td>0.065133</td>\n",
       "      <td>0.001191</td>\n",
       "      <td>0.028612</td>\n",
       "      <td>0.185722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bit_8</th>\n",
       "      <td>0.060250</td>\n",
       "      <td>0.027675</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.221732</td>\n",
       "      <td>0.042426</td>\n",
       "      <td>0.127507</td>\n",
       "      <td>0.114649</td>\n",
       "      <td>0.072877</td>\n",
       "      <td>0.168621</td>\n",
       "      <td>0.345448</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158420</td>\n",
       "      <td>0.014074</td>\n",
       "      <td>0.089367</td>\n",
       "      <td>0.061572</td>\n",
       "      <td>0.364084</td>\n",
       "      <td>0.142961</td>\n",
       "      <td>0.153835</td>\n",
       "      <td>0.123936</td>\n",
       "      <td>0.095435</td>\n",
       "      <td>0.185521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bit_14</th>\n",
       "      <td>0.009891</td>\n",
       "      <td>0.014926</td>\n",
       "      <td>0.221732</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.070198</td>\n",
       "      <td>0.036017</td>\n",
       "      <td>0.057341</td>\n",
       "      <td>0.065951</td>\n",
       "      <td>0.071944</td>\n",
       "      <td>0.050997</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077259</td>\n",
       "      <td>0.068002</td>\n",
       "      <td>0.088052</td>\n",
       "      <td>0.069185</td>\n",
       "      <td>0.086880</td>\n",
       "      <td>0.029150</td>\n",
       "      <td>0.072931</td>\n",
       "      <td>0.069101</td>\n",
       "      <td>0.029323</td>\n",
       "      <td>0.024528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bit_15</th>\n",
       "      <td>0.011247</td>\n",
       "      <td>0.037057</td>\n",
       "      <td>0.042426</td>\n",
       "      <td>0.070198</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.026488</td>\n",
       "      <td>0.101954</td>\n",
       "      <td>0.021461</td>\n",
       "      <td>0.008593</td>\n",
       "      <td>0.030356</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075230</td>\n",
       "      <td>0.048196</td>\n",
       "      <td>0.158765</td>\n",
       "      <td>0.048643</td>\n",
       "      <td>0.004722</td>\n",
       "      <td>0.053132</td>\n",
       "      <td>0.059986</td>\n",
       "      <td>0.067215</td>\n",
       "      <td>0.083452</td>\n",
       "      <td>0.009351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bit_1009</th>\n",
       "      <td>0.077911</td>\n",
       "      <td>0.042160</td>\n",
       "      <td>0.142961</td>\n",
       "      <td>0.029150</td>\n",
       "      <td>0.053132</td>\n",
       "      <td>0.669497</td>\n",
       "      <td>0.724743</td>\n",
       "      <td>0.031466</td>\n",
       "      <td>0.005697</td>\n",
       "      <td>0.145736</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003805</td>\n",
       "      <td>0.090313</td>\n",
       "      <td>0.006980</td>\n",
       "      <td>0.007684</td>\n",
       "      <td>0.077589</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.021332</td>\n",
       "      <td>0.079413</td>\n",
       "      <td>0.382081</td>\n",
       "      <td>0.104191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bit_1010</th>\n",
       "      <td>0.311692</td>\n",
       "      <td>0.065133</td>\n",
       "      <td>0.153835</td>\n",
       "      <td>0.072931</td>\n",
       "      <td>0.059986</td>\n",
       "      <td>0.003054</td>\n",
       "      <td>0.042885</td>\n",
       "      <td>0.226246</td>\n",
       "      <td>0.460361</td>\n",
       "      <td>0.145991</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077332</td>\n",
       "      <td>0.486556</td>\n",
       "      <td>0.045322</td>\n",
       "      <td>0.187867</td>\n",
       "      <td>0.144834</td>\n",
       "      <td>0.021332</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750003</td>\n",
       "      <td>0.003429</td>\n",
       "      <td>0.272967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bit_1016</th>\n",
       "      <td>0.403763</td>\n",
       "      <td>0.001191</td>\n",
       "      <td>0.123936</td>\n",
       "      <td>0.069101</td>\n",
       "      <td>0.067215</td>\n",
       "      <td>0.069502</td>\n",
       "      <td>0.025609</td>\n",
       "      <td>0.222045</td>\n",
       "      <td>0.515797</td>\n",
       "      <td>0.216998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075580</td>\n",
       "      <td>0.642871</td>\n",
       "      <td>0.047347</td>\n",
       "      <td>0.196146</td>\n",
       "      <td>0.128637</td>\n",
       "      <td>0.079413</td>\n",
       "      <td>0.750003</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.015121</td>\n",
       "      <td>0.416002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bit_1017</th>\n",
       "      <td>0.021016</td>\n",
       "      <td>0.028612</td>\n",
       "      <td>0.095435</td>\n",
       "      <td>0.029323</td>\n",
       "      <td>0.083452</td>\n",
       "      <td>0.202189</td>\n",
       "      <td>0.361635</td>\n",
       "      <td>0.070850</td>\n",
       "      <td>0.023592</td>\n",
       "      <td>0.096186</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010623</td>\n",
       "      <td>0.018075</td>\n",
       "      <td>0.021782</td>\n",
       "      <td>0.012167</td>\n",
       "      <td>0.033495</td>\n",
       "      <td>0.382081</td>\n",
       "      <td>0.003429</td>\n",
       "      <td>0.015121</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bit_1019</th>\n",
       "      <td>0.351924</td>\n",
       "      <td>0.185722</td>\n",
       "      <td>0.185521</td>\n",
       "      <td>0.024528</td>\n",
       "      <td>0.009351</td>\n",
       "      <td>0.084341</td>\n",
       "      <td>0.061936</td>\n",
       "      <td>0.116149</td>\n",
       "      <td>0.267611</td>\n",
       "      <td>0.129015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067297</td>\n",
       "      <td>0.304856</td>\n",
       "      <td>0.019219</td>\n",
       "      <td>0.108960</td>\n",
       "      <td>0.108114</td>\n",
       "      <td>0.104191</td>\n",
       "      <td>0.272967</td>\n",
       "      <td>0.416002</td>\n",
       "      <td>0.027988</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>209 rows Ã— 209 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Bit_1     Bit_4     Bit_8    Bit_14    Bit_15    Bit_25  \\\n",
       "Bit_1     1.000000  0.023343  0.060250  0.009891  0.011247  0.051526   \n",
       "Bit_4     0.023343  1.000000  0.027675  0.014926  0.037057  0.026979   \n",
       "Bit_8     0.060250  0.027675  1.000000  0.221732  0.042426  0.127507   \n",
       "Bit_14    0.009891  0.014926  0.221732  1.000000  0.070198  0.036017   \n",
       "Bit_15    0.011247  0.037057  0.042426  0.070198  1.000000  0.026488   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "Bit_1009  0.077911  0.042160  0.142961  0.029150  0.053132  0.669497   \n",
       "Bit_1010  0.311692  0.065133  0.153835  0.072931  0.059986  0.003054   \n",
       "Bit_1016  0.403763  0.001191  0.123936  0.069101  0.067215  0.069502   \n",
       "Bit_1017  0.021016  0.028612  0.095435  0.029323  0.083452  0.202189   \n",
       "Bit_1019  0.351924  0.185722  0.185521  0.024528  0.009351  0.084341   \n",
       "\n",
       "            Bit_31    Bit_33    Bit_36    Bit_41  ...   Bit_967   Bit_971  \\\n",
       "Bit_1     0.056199  0.309418  0.204014  0.181086  ...  0.111018  0.466243   \n",
       "Bit_4     0.016688  0.129453  0.123931  0.068172  ...  0.079457  0.007767   \n",
       "Bit_8     0.114649  0.072877  0.168621  0.345448  ...  0.158420  0.014074   \n",
       "Bit_14    0.057341  0.065951  0.071944  0.050997  ...  0.077259  0.068002   \n",
       "Bit_15    0.101954  0.021461  0.008593  0.030356  ...  0.075230  0.048196   \n",
       "...            ...       ...       ...       ...  ...       ...       ...   \n",
       "Bit_1009  0.724743  0.031466  0.005697  0.145736  ...  0.003805  0.090313   \n",
       "Bit_1010  0.042885  0.226246  0.460361  0.145991  ...  0.077332  0.486556   \n",
       "Bit_1016  0.025609  0.222045  0.515797  0.216998  ...  0.075580  0.642871   \n",
       "Bit_1017  0.361635  0.070850  0.023592  0.096186  ...  0.010623  0.018075   \n",
       "Bit_1019  0.061936  0.116149  0.267611  0.129015  ...  0.067297  0.304856   \n",
       "\n",
       "           Bit_980   Bit_997   Bit_999  Bit_1009  Bit_1010  Bit_1016  \\\n",
       "Bit_1     0.044719  0.087555  0.194876  0.077911  0.311692  0.403763   \n",
       "Bit_4     0.014474  0.081022  0.017261  0.042160  0.065133  0.001191   \n",
       "Bit_8     0.089367  0.061572  0.364084  0.142961  0.153835  0.123936   \n",
       "Bit_14    0.088052  0.069185  0.086880  0.029150  0.072931  0.069101   \n",
       "Bit_15    0.158765  0.048643  0.004722  0.053132  0.059986  0.067215   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "Bit_1009  0.006980  0.007684  0.077589  1.000000  0.021332  0.079413   \n",
       "Bit_1010  0.045322  0.187867  0.144834  0.021332  1.000000  0.750003   \n",
       "Bit_1016  0.047347  0.196146  0.128637  0.079413  0.750003  1.000000   \n",
       "Bit_1017  0.021782  0.012167  0.033495  0.382081  0.003429  0.015121   \n",
       "Bit_1019  0.019219  0.108960  0.108114  0.104191  0.272967  0.416002   \n",
       "\n",
       "          Bit_1017  Bit_1019  \n",
       "Bit_1     0.021016  0.351924  \n",
       "Bit_4     0.028612  0.185722  \n",
       "Bit_8     0.095435  0.185521  \n",
       "Bit_14    0.029323  0.024528  \n",
       "Bit_15    0.083452  0.009351  \n",
       "...            ...       ...  \n",
       "Bit_1009  0.382081  0.104191  \n",
       "Bit_1010  0.003429  0.272967  \n",
       "Bit_1016  0.015121  0.416002  \n",
       "Bit_1017  1.000000  0.027988  \n",
       "Bit_1019  0.027988  1.000000  \n",
       "\n",
       "[209 rows x 209 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cor_df = x_tr_const_and_nearcont.corr().abs()\n",
    "cor_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bit_1</th>\n",
       "      <th>Bit_4</th>\n",
       "      <th>Bit_8</th>\n",
       "      <th>Bit_14</th>\n",
       "      <th>Bit_15</th>\n",
       "      <th>Bit_25</th>\n",
       "      <th>Bit_31</th>\n",
       "      <th>Bit_33</th>\n",
       "      <th>Bit_36</th>\n",
       "      <th>Bit_41</th>\n",
       "      <th>...</th>\n",
       "      <th>Bit_967</th>\n",
       "      <th>Bit_971</th>\n",
       "      <th>Bit_980</th>\n",
       "      <th>Bit_997</th>\n",
       "      <th>Bit_999</th>\n",
       "      <th>Bit_1009</th>\n",
       "      <th>Bit_1010</th>\n",
       "      <th>Bit_1016</th>\n",
       "      <th>Bit_1017</th>\n",
       "      <th>Bit_1019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bit_1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.023343</td>\n",
       "      <td>0.060250</td>\n",
       "      <td>0.009891</td>\n",
       "      <td>0.011247</td>\n",
       "      <td>0.051526</td>\n",
       "      <td>0.056199</td>\n",
       "      <td>0.309418</td>\n",
       "      <td>0.204014</td>\n",
       "      <td>0.181086</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111018</td>\n",
       "      <td>0.466243</td>\n",
       "      <td>0.044719</td>\n",
       "      <td>0.087555</td>\n",
       "      <td>0.194876</td>\n",
       "      <td>0.077911</td>\n",
       "      <td>0.311692</td>\n",
       "      <td>0.403763</td>\n",
       "      <td>0.021016</td>\n",
       "      <td>0.351924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bit_4</th>\n",
       "      <td>0.023343</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027675</td>\n",
       "      <td>0.014926</td>\n",
       "      <td>0.037057</td>\n",
       "      <td>0.026979</td>\n",
       "      <td>0.016688</td>\n",
       "      <td>0.129453</td>\n",
       "      <td>0.123931</td>\n",
       "      <td>0.068172</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079457</td>\n",
       "      <td>0.007767</td>\n",
       "      <td>0.014474</td>\n",
       "      <td>0.081022</td>\n",
       "      <td>0.017261</td>\n",
       "      <td>0.042160</td>\n",
       "      <td>0.065133</td>\n",
       "      <td>0.001191</td>\n",
       "      <td>0.028612</td>\n",
       "      <td>0.185722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bit_8</th>\n",
       "      <td>0.060250</td>\n",
       "      <td>0.027675</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.221732</td>\n",
       "      <td>0.042426</td>\n",
       "      <td>0.127507</td>\n",
       "      <td>0.114649</td>\n",
       "      <td>0.072877</td>\n",
       "      <td>0.168621</td>\n",
       "      <td>0.345448</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158420</td>\n",
       "      <td>0.014074</td>\n",
       "      <td>0.089367</td>\n",
       "      <td>0.061572</td>\n",
       "      <td>0.364084</td>\n",
       "      <td>0.142961</td>\n",
       "      <td>0.153835</td>\n",
       "      <td>0.123936</td>\n",
       "      <td>0.095435</td>\n",
       "      <td>0.185521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bit_14</th>\n",
       "      <td>0.009891</td>\n",
       "      <td>0.014926</td>\n",
       "      <td>0.221732</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.070198</td>\n",
       "      <td>0.036017</td>\n",
       "      <td>0.057341</td>\n",
       "      <td>0.065951</td>\n",
       "      <td>0.071944</td>\n",
       "      <td>0.050997</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077259</td>\n",
       "      <td>0.068002</td>\n",
       "      <td>0.088052</td>\n",
       "      <td>0.069185</td>\n",
       "      <td>0.086880</td>\n",
       "      <td>0.029150</td>\n",
       "      <td>0.072931</td>\n",
       "      <td>0.069101</td>\n",
       "      <td>0.029323</td>\n",
       "      <td>0.024528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bit_15</th>\n",
       "      <td>0.011247</td>\n",
       "      <td>0.037057</td>\n",
       "      <td>0.042426</td>\n",
       "      <td>0.070198</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.026488</td>\n",
       "      <td>0.101954</td>\n",
       "      <td>0.021461</td>\n",
       "      <td>0.008593</td>\n",
       "      <td>0.030356</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075230</td>\n",
       "      <td>0.048196</td>\n",
       "      <td>0.158765</td>\n",
       "      <td>0.048643</td>\n",
       "      <td>0.004722</td>\n",
       "      <td>0.053132</td>\n",
       "      <td>0.059986</td>\n",
       "      <td>0.067215</td>\n",
       "      <td>0.083452</td>\n",
       "      <td>0.009351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bit_1009</th>\n",
       "      <td>0.077911</td>\n",
       "      <td>0.042160</td>\n",
       "      <td>0.142961</td>\n",
       "      <td>0.029150</td>\n",
       "      <td>0.053132</td>\n",
       "      <td>0.669497</td>\n",
       "      <td>0.724743</td>\n",
       "      <td>0.031466</td>\n",
       "      <td>0.005697</td>\n",
       "      <td>0.145736</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003805</td>\n",
       "      <td>0.090313</td>\n",
       "      <td>0.006980</td>\n",
       "      <td>0.007684</td>\n",
       "      <td>0.077589</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.021332</td>\n",
       "      <td>0.079413</td>\n",
       "      <td>0.382081</td>\n",
       "      <td>0.104191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bit_1010</th>\n",
       "      <td>0.311692</td>\n",
       "      <td>0.065133</td>\n",
       "      <td>0.153835</td>\n",
       "      <td>0.072931</td>\n",
       "      <td>0.059986</td>\n",
       "      <td>0.003054</td>\n",
       "      <td>0.042885</td>\n",
       "      <td>0.226246</td>\n",
       "      <td>0.460361</td>\n",
       "      <td>0.145991</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077332</td>\n",
       "      <td>0.486556</td>\n",
       "      <td>0.045322</td>\n",
       "      <td>0.187867</td>\n",
       "      <td>0.144834</td>\n",
       "      <td>0.021332</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750003</td>\n",
       "      <td>0.003429</td>\n",
       "      <td>0.272967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bit_1016</th>\n",
       "      <td>0.403763</td>\n",
       "      <td>0.001191</td>\n",
       "      <td>0.123936</td>\n",
       "      <td>0.069101</td>\n",
       "      <td>0.067215</td>\n",
       "      <td>0.069502</td>\n",
       "      <td>0.025609</td>\n",
       "      <td>0.222045</td>\n",
       "      <td>0.515797</td>\n",
       "      <td>0.216998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075580</td>\n",
       "      <td>0.642871</td>\n",
       "      <td>0.047347</td>\n",
       "      <td>0.196146</td>\n",
       "      <td>0.128637</td>\n",
       "      <td>0.079413</td>\n",
       "      <td>0.750003</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.015121</td>\n",
       "      <td>0.416002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bit_1017</th>\n",
       "      <td>0.021016</td>\n",
       "      <td>0.028612</td>\n",
       "      <td>0.095435</td>\n",
       "      <td>0.029323</td>\n",
       "      <td>0.083452</td>\n",
       "      <td>0.202189</td>\n",
       "      <td>0.361635</td>\n",
       "      <td>0.070850</td>\n",
       "      <td>0.023592</td>\n",
       "      <td>0.096186</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010623</td>\n",
       "      <td>0.018075</td>\n",
       "      <td>0.021782</td>\n",
       "      <td>0.012167</td>\n",
       "      <td>0.033495</td>\n",
       "      <td>0.382081</td>\n",
       "      <td>0.003429</td>\n",
       "      <td>0.015121</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bit_1019</th>\n",
       "      <td>0.351924</td>\n",
       "      <td>0.185722</td>\n",
       "      <td>0.185521</td>\n",
       "      <td>0.024528</td>\n",
       "      <td>0.009351</td>\n",
       "      <td>0.084341</td>\n",
       "      <td>0.061936</td>\n",
       "      <td>0.116149</td>\n",
       "      <td>0.267611</td>\n",
       "      <td>0.129015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067297</td>\n",
       "      <td>0.304856</td>\n",
       "      <td>0.019219</td>\n",
       "      <td>0.108960</td>\n",
       "      <td>0.108114</td>\n",
       "      <td>0.104191</td>\n",
       "      <td>0.272967</td>\n",
       "      <td>0.416002</td>\n",
       "      <td>0.027988</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>209 rows Ã— 209 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Bit_1     Bit_4     Bit_8    Bit_14    Bit_15    Bit_25  \\\n",
       "Bit_1     1.000000  0.023343  0.060250  0.009891  0.011247  0.051526   \n",
       "Bit_4     0.023343  1.000000  0.027675  0.014926  0.037057  0.026979   \n",
       "Bit_8     0.060250  0.027675  1.000000  0.221732  0.042426  0.127507   \n",
       "Bit_14    0.009891  0.014926  0.221732  1.000000  0.070198  0.036017   \n",
       "Bit_15    0.011247  0.037057  0.042426  0.070198  1.000000  0.026488   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "Bit_1009  0.077911  0.042160  0.142961  0.029150  0.053132  0.669497   \n",
       "Bit_1010  0.311692  0.065133  0.153835  0.072931  0.059986  0.003054   \n",
       "Bit_1016  0.403763  0.001191  0.123936  0.069101  0.067215  0.069502   \n",
       "Bit_1017  0.021016  0.028612  0.095435  0.029323  0.083452  0.202189   \n",
       "Bit_1019  0.351924  0.185722  0.185521  0.024528  0.009351  0.084341   \n",
       "\n",
       "            Bit_31    Bit_33    Bit_36    Bit_41  ...   Bit_967   Bit_971  \\\n",
       "Bit_1     0.056199  0.309418  0.204014  0.181086  ...  0.111018  0.466243   \n",
       "Bit_4     0.016688  0.129453  0.123931  0.068172  ...  0.079457  0.007767   \n",
       "Bit_8     0.114649  0.072877  0.168621  0.345448  ...  0.158420  0.014074   \n",
       "Bit_14    0.057341  0.065951  0.071944  0.050997  ...  0.077259  0.068002   \n",
       "Bit_15    0.101954  0.021461  0.008593  0.030356  ...  0.075230  0.048196   \n",
       "...            ...       ...       ...       ...  ...       ...       ...   \n",
       "Bit_1009  0.724743  0.031466  0.005697  0.145736  ...  0.003805  0.090313   \n",
       "Bit_1010  0.042885  0.226246  0.460361  0.145991  ...  0.077332  0.486556   \n",
       "Bit_1016  0.025609  0.222045  0.515797  0.216998  ...  0.075580  0.642871   \n",
       "Bit_1017  0.361635  0.070850  0.023592  0.096186  ...  0.010623  0.018075   \n",
       "Bit_1019  0.061936  0.116149  0.267611  0.129015  ...  0.067297  0.304856   \n",
       "\n",
       "           Bit_980   Bit_997   Bit_999  Bit_1009  Bit_1010  Bit_1016  \\\n",
       "Bit_1     0.044719  0.087555  0.194876  0.077911  0.311692  0.403763   \n",
       "Bit_4     0.014474  0.081022  0.017261  0.042160  0.065133  0.001191   \n",
       "Bit_8     0.089367  0.061572  0.364084  0.142961  0.153835  0.123936   \n",
       "Bit_14    0.088052  0.069185  0.086880  0.029150  0.072931  0.069101   \n",
       "Bit_15    0.158765  0.048643  0.004722  0.053132  0.059986  0.067215   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "Bit_1009  0.006980  0.007684  0.077589  1.000000  0.021332  0.079413   \n",
       "Bit_1010  0.045322  0.187867  0.144834  0.021332  1.000000  0.750003   \n",
       "Bit_1016  0.047347  0.196146  0.128637  0.079413  0.750003  1.000000   \n",
       "Bit_1017  0.021782  0.012167  0.033495  0.382081  0.003429  0.015121   \n",
       "Bit_1019  0.019219  0.108960  0.108114  0.104191  0.272967  0.416002   \n",
       "\n",
       "          Bit_1017  Bit_1019  \n",
       "Bit_1     0.021016  0.351924  \n",
       "Bit_4     0.028612  0.185722  \n",
       "Bit_8     0.095435  0.185521  \n",
       "Bit_14    0.029323  0.024528  \n",
       "Bit_15    0.083452  0.009351  \n",
       "...            ...       ...  \n",
       "Bit_1009  0.382081  0.104191  \n",
       "Bit_1010  0.003429  0.272967  \n",
       "Bit_1016  0.015121  0.416002  \n",
       "Bit_1017  1.000000  0.027988  \n",
       "Bit_1019  0.027988  1.000000  \n",
       "\n",
       "[209 rows x 209 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cor_df = x_tr_const_and_nearcont.corr().abs()\n",
    "cor_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask=np.triu(np.ones_like(cor_df, dtype=bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bit_1</th>\n",
       "      <th>Bit_4</th>\n",
       "      <th>Bit_8</th>\n",
       "      <th>Bit_14</th>\n",
       "      <th>Bit_15</th>\n",
       "      <th>Bit_25</th>\n",
       "      <th>Bit_31</th>\n",
       "      <th>Bit_33</th>\n",
       "      <th>Bit_36</th>\n",
       "      <th>Bit_41</th>\n",
       "      <th>...</th>\n",
       "      <th>Bit_967</th>\n",
       "      <th>Bit_971</th>\n",
       "      <th>Bit_980</th>\n",
       "      <th>Bit_997</th>\n",
       "      <th>Bit_999</th>\n",
       "      <th>Bit_1009</th>\n",
       "      <th>Bit_1010</th>\n",
       "      <th>Bit_1016</th>\n",
       "      <th>Bit_1017</th>\n",
       "      <th>Bit_1019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bit_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bit_4</th>\n",
       "      <td>0.023343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bit_8</th>\n",
       "      <td>0.060250</td>\n",
       "      <td>0.027675</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bit_14</th>\n",
       "      <td>0.009891</td>\n",
       "      <td>0.014926</td>\n",
       "      <td>0.221732</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bit_15</th>\n",
       "      <td>0.011247</td>\n",
       "      <td>0.037057</td>\n",
       "      <td>0.042426</td>\n",
       "      <td>0.070198</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bit_1009</th>\n",
       "      <td>0.077911</td>\n",
       "      <td>0.042160</td>\n",
       "      <td>0.142961</td>\n",
       "      <td>0.029150</td>\n",
       "      <td>0.053132</td>\n",
       "      <td>0.669497</td>\n",
       "      <td>0.724743</td>\n",
       "      <td>0.031466</td>\n",
       "      <td>0.005697</td>\n",
       "      <td>0.145736</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003805</td>\n",
       "      <td>0.090313</td>\n",
       "      <td>0.006980</td>\n",
       "      <td>0.007684</td>\n",
       "      <td>0.077589</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bit_1010</th>\n",
       "      <td>0.311692</td>\n",
       "      <td>0.065133</td>\n",
       "      <td>0.153835</td>\n",
       "      <td>0.072931</td>\n",
       "      <td>0.059986</td>\n",
       "      <td>0.003054</td>\n",
       "      <td>0.042885</td>\n",
       "      <td>0.226246</td>\n",
       "      <td>0.460361</td>\n",
       "      <td>0.145991</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077332</td>\n",
       "      <td>0.486556</td>\n",
       "      <td>0.045322</td>\n",
       "      <td>0.187867</td>\n",
       "      <td>0.144834</td>\n",
       "      <td>0.021332</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bit_1016</th>\n",
       "      <td>0.403763</td>\n",
       "      <td>0.001191</td>\n",
       "      <td>0.123936</td>\n",
       "      <td>0.069101</td>\n",
       "      <td>0.067215</td>\n",
       "      <td>0.069502</td>\n",
       "      <td>0.025609</td>\n",
       "      <td>0.222045</td>\n",
       "      <td>0.515797</td>\n",
       "      <td>0.216998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075580</td>\n",
       "      <td>0.642871</td>\n",
       "      <td>0.047347</td>\n",
       "      <td>0.196146</td>\n",
       "      <td>0.128637</td>\n",
       "      <td>0.079413</td>\n",
       "      <td>0.750003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bit_1017</th>\n",
       "      <td>0.021016</td>\n",
       "      <td>0.028612</td>\n",
       "      <td>0.095435</td>\n",
       "      <td>0.029323</td>\n",
       "      <td>0.083452</td>\n",
       "      <td>0.202189</td>\n",
       "      <td>0.361635</td>\n",
       "      <td>0.070850</td>\n",
       "      <td>0.023592</td>\n",
       "      <td>0.096186</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010623</td>\n",
       "      <td>0.018075</td>\n",
       "      <td>0.021782</td>\n",
       "      <td>0.012167</td>\n",
       "      <td>0.033495</td>\n",
       "      <td>0.382081</td>\n",
       "      <td>0.003429</td>\n",
       "      <td>0.015121</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bit_1019</th>\n",
       "      <td>0.351924</td>\n",
       "      <td>0.185722</td>\n",
       "      <td>0.185521</td>\n",
       "      <td>0.024528</td>\n",
       "      <td>0.009351</td>\n",
       "      <td>0.084341</td>\n",
       "      <td>0.061936</td>\n",
       "      <td>0.116149</td>\n",
       "      <td>0.267611</td>\n",
       "      <td>0.129015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067297</td>\n",
       "      <td>0.304856</td>\n",
       "      <td>0.019219</td>\n",
       "      <td>0.108960</td>\n",
       "      <td>0.108114</td>\n",
       "      <td>0.104191</td>\n",
       "      <td>0.272967</td>\n",
       "      <td>0.416002</td>\n",
       "      <td>0.027988</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>209 rows Ã— 209 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Bit_1     Bit_4     Bit_8    Bit_14    Bit_15    Bit_25  \\\n",
       "Bit_1          NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "Bit_4     0.023343       NaN       NaN       NaN       NaN       NaN   \n",
       "Bit_8     0.060250  0.027675       NaN       NaN       NaN       NaN   \n",
       "Bit_14    0.009891  0.014926  0.221732       NaN       NaN       NaN   \n",
       "Bit_15    0.011247  0.037057  0.042426  0.070198       NaN       NaN   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "Bit_1009  0.077911  0.042160  0.142961  0.029150  0.053132  0.669497   \n",
       "Bit_1010  0.311692  0.065133  0.153835  0.072931  0.059986  0.003054   \n",
       "Bit_1016  0.403763  0.001191  0.123936  0.069101  0.067215  0.069502   \n",
       "Bit_1017  0.021016  0.028612  0.095435  0.029323  0.083452  0.202189   \n",
       "Bit_1019  0.351924  0.185722  0.185521  0.024528  0.009351  0.084341   \n",
       "\n",
       "            Bit_31    Bit_33    Bit_36    Bit_41  ...   Bit_967   Bit_971  \\\n",
       "Bit_1          NaN       NaN       NaN       NaN  ...       NaN       NaN   \n",
       "Bit_4          NaN       NaN       NaN       NaN  ...       NaN       NaN   \n",
       "Bit_8          NaN       NaN       NaN       NaN  ...       NaN       NaN   \n",
       "Bit_14         NaN       NaN       NaN       NaN  ...       NaN       NaN   \n",
       "Bit_15         NaN       NaN       NaN       NaN  ...       NaN       NaN   \n",
       "...            ...       ...       ...       ...  ...       ...       ...   \n",
       "Bit_1009  0.724743  0.031466  0.005697  0.145736  ...  0.003805  0.090313   \n",
       "Bit_1010  0.042885  0.226246  0.460361  0.145991  ...  0.077332  0.486556   \n",
       "Bit_1016  0.025609  0.222045  0.515797  0.216998  ...  0.075580  0.642871   \n",
       "Bit_1017  0.361635  0.070850  0.023592  0.096186  ...  0.010623  0.018075   \n",
       "Bit_1019  0.061936  0.116149  0.267611  0.129015  ...  0.067297  0.304856   \n",
       "\n",
       "           Bit_980   Bit_997   Bit_999  Bit_1009  Bit_1010  Bit_1016  \\\n",
       "Bit_1          NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "Bit_4          NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "Bit_8          NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "Bit_14         NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "Bit_15         NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "Bit_1009  0.006980  0.007684  0.077589       NaN       NaN       NaN   \n",
       "Bit_1010  0.045322  0.187867  0.144834  0.021332       NaN       NaN   \n",
       "Bit_1016  0.047347  0.196146  0.128637  0.079413  0.750003       NaN   \n",
       "Bit_1017  0.021782  0.012167  0.033495  0.382081  0.003429  0.015121   \n",
       "Bit_1019  0.019219  0.108960  0.108114  0.104191  0.272967  0.416002   \n",
       "\n",
       "          Bit_1017  Bit_1019  \n",
       "Bit_1          NaN       NaN  \n",
       "Bit_4          NaN       NaN  \n",
       "Bit_8          NaN       NaN  \n",
       "Bit_14         NaN       NaN  \n",
       "Bit_15         NaN       NaN  \n",
       "...            ...       ...  \n",
       "Bit_1009       NaN       NaN  \n",
       "Bit_1010       NaN       NaN  \n",
       "Bit_1016       NaN       NaN  \n",
       "Bit_1017       NaN       NaN  \n",
       "Bit_1019  0.027988       NaN  \n",
       "\n",
       "[209 rows x 209 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tri_df=cor_df.mask(mask)\n",
    "tri_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bit_109', 'Bit_238', 'Bit_331', 'Bit_607']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_drop=[c for c in tri_df.columns if any(tri_df[c]>0.95) ]\n",
    "to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_df_cor=x_tr_const_and_nearcont.drop(to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bit_1</th>\n",
       "      <th>Bit_4</th>\n",
       "      <th>Bit_8</th>\n",
       "      <th>Bit_14</th>\n",
       "      <th>Bit_15</th>\n",
       "      <th>Bit_25</th>\n",
       "      <th>Bit_31</th>\n",
       "      <th>Bit_33</th>\n",
       "      <th>Bit_36</th>\n",
       "      <th>Bit_41</th>\n",
       "      <th>...</th>\n",
       "      <th>Bit_967</th>\n",
       "      <th>Bit_971</th>\n",
       "      <th>Bit_980</th>\n",
       "      <th>Bit_997</th>\n",
       "      <th>Bit_999</th>\n",
       "      <th>Bit_1009</th>\n",
       "      <th>Bit_1010</th>\n",
       "      <th>Bit_1016</th>\n",
       "      <th>Bit_1017</th>\n",
       "      <th>Bit_1019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1400 rows Ã— 205 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Bit_1  Bit_4  Bit_8  Bit_14  Bit_15  Bit_25  Bit_31  Bit_33  Bit_36  \\\n",
       "0         1      0      0       0       0       0       0       1       0   \n",
       "1         1      0      0       0       0       0       0       0       0   \n",
       "2         0      0      1       0       1       0       0       1       0   \n",
       "3         0      0      0       0       1       0       0       1       0   \n",
       "4         0      0      1       0       0       0       0       1       0   \n",
       "...     ...    ...    ...     ...     ...     ...     ...     ...     ...   \n",
       "1395      1      0      0       0       0       0       0       1       1   \n",
       "1396      1      0      0       0       0       0       0       1       1   \n",
       "1397      1      0      0       0       0       0       0       1       1   \n",
       "1398      1      1      1       0       0       0       0       1       0   \n",
       "1399      1      0      0       0       0       0       0       1       1   \n",
       "\n",
       "      Bit_41  ...  Bit_967  Bit_971  Bit_980  Bit_997  Bit_999  Bit_1009  \\\n",
       "0          1  ...        0        0        0        0        0         0   \n",
       "1          1  ...        0        0        0        0        0         0   \n",
       "2          0  ...        0        0        0        0        0         0   \n",
       "3          1  ...        0        0        0        0        0         0   \n",
       "4          0  ...        0        0        0        0        0         0   \n",
       "...      ...  ...      ...      ...      ...      ...      ...       ...   \n",
       "1395       0  ...        0        1        0        1        0         0   \n",
       "1396       0  ...        0        1        0        1        0         0   \n",
       "1397       0  ...        0        1        0        1        0         0   \n",
       "1398       0  ...        0        1        0        0        0         0   \n",
       "1399       0  ...        0        0        0        1        0         0   \n",
       "\n",
       "      Bit_1010  Bit_1016  Bit_1017  Bit_1019  \n",
       "0            0         0         0         0  \n",
       "1            0         0         0         0  \n",
       "2            0         0         0         0  \n",
       "3            0         0         0         0  \n",
       "4            0         0         0         0  \n",
       "...        ...       ...       ...       ...  \n",
       "1395         1         1         0         1  \n",
       "1396         1         1         0         1  \n",
       "1397         1         1         0         1  \n",
       "1398         0         0         0         1  \n",
       "1399         1         1         0         1  \n",
       "\n",
       "[1400 rows x 205 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_df_cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor(learning_rate=0.01, max_depth=10, n_estimators=1000,\n",
       "                          random_state=42, subsample=0.5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(learning_rate=0.01, max_depth=10, n_estimators=1000,\n",
       "                          random_state=42, subsample=0.5)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingRegressor(learning_rate=0.01, max_depth=10, n_estimators=1000,\n",
       "                          random_state=42, subsample=0.5)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.fit(reduced_df_cor, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_CV_GBR = cross_val_predict(estimator, reduced_df_cor, y_tr, cv=cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q2_CV = round(r2_score(y_tr, y_pred_CV_GBR), 2)\n",
    "Q2_CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE_CV=round(np.sqrt(mean_squared_error(y_tr, y_pred_CV_GBR)), 2)\n",
    "RMSE_CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "205"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_name_reduced_df_cor = reduced_df_cor.columns.tolist()\n",
    "len(feature_name_reduced_df_cor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction for test set's molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ts=desc_ts[feature_name_reduced_df_cor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ts = np.array(y_ts, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_GBR = estimator.predict(x_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q2_TS = round(r2_score(y_ts, y_pred_GBR), 2)\n",
    "Q2_TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE_TS=round(np.sqrt(mean_squared_error(y_ts, y_pred_GBR)), 2)\n",
    "RMSE_TS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Permutation-importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = SelectFromModel(PermutationImportance(GradientBoostingRegressor(), cv=cv),threshold=0.005,).fit(reduced_df_cor, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1400, 33)"
      ]
     },
     "execution_count": 835,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_permut_import = sel.transform(reduced_df_cor)\n",
    "X_permut_import.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Bit_36', 'Bit_90', 'Bit_117', 'Bit_119', 'Bit_128', 'Bit_197',\n",
       "       'Bit_229', 'Bit_243', 'Bit_250', 'Bit_301', 'Bit_389', 'Bit_408',\n",
       "       'Bit_419', 'Bit_486', 'Bit_494', 'Bit_511', 'Bit_549', 'Bit_559',\n",
       "       'Bit_638', 'Bit_662', 'Bit_708', 'Bit_714', 'Bit_721', 'Bit_726',\n",
       "       'Bit_736', 'Bit_759', 'Bit_831', 'Bit_843', 'Bit_852', 'Bit_878',\n",
       "       'Bit_910', 'Bit_922', 'Bit_955'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 836,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_idx = sel.get_support()\n",
    "feature_name = reduced_df_cor.columns[feature_idx]\n",
    "feature_name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-54 {color: black;}#sk-container-id-54 pre{padding: 0;}#sk-container-id-54 div.sk-toggleable {background-color: white;}#sk-container-id-54 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-54 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-54 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-54 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-54 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-54 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-54 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-54 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-54 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-54 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-54 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-54 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-54 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-54 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-54 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-54 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-54 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-54 div.sk-item {position: relative;z-index: 1;}#sk-container-id-54 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-54 div.sk-item::before, #sk-container-id-54 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-54 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-54 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-54 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-54 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-54 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-54 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-54 div.sk-label-container {text-align: center;}#sk-container-id-54 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-54 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-54\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor(learning_rate=0.01, max_depth=10, n_estimators=1000,\n",
       "                          random_state=42, subsample=0.5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-87\" type=\"checkbox\" checked><label for=\"sk-estimator-id-87\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(learning_rate=0.01, max_depth=10, n_estimators=1000,\n",
       "                          random_state=42, subsample=0.5)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingRegressor(learning_rate=0.01, max_depth=10, n_estimators=1000,\n",
       "                          random_state=42, subsample=0.5)"
      ]
     },
     "execution_count": 837,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.fit(X_permut_import, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_CV_GBR = cross_val_predict(estimator, X_permut_import, y_tr, cv=cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.59"
      ]
     },
     "execution_count": 839,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q2_CV = round(r2_score(y_tr, y_pred_CV_GBR), 2)\n",
    "Q2_CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78"
      ]
     },
     "execution_count": 840,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE_CV=round(np.sqrt(mean_squared_error(y_tr, y_pred_CV_GBR)), 2)\n",
    "RMSE_CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction for test set's molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ts=desc_ts[feature_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ts = np.array(y_ts, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_GBR = estimator.predict(x_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64"
      ]
     },
     "execution_count": 844,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q2_TS = round(r2_score(y_ts, y_pred_GBR), 2)\n",
    "Q2_TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74"
      ]
     },
     "execution_count": 845,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE_TS=round(np.sqrt(mean_squared_error(y_ts, y_pred_GBR)), 2)\n",
    "RMSE_TS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Recursive feature elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-56 {color: black;}#sk-container-id-56 pre{padding: 0;}#sk-container-id-56 div.sk-toggleable {background-color: white;}#sk-container-id-56 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-56 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-56 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-56 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-56 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-56 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-56 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-56 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-56 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-56 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-56 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-56 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-56 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-56 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-56 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-56 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-56 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-56 div.sk-item {position: relative;z-index: 1;}#sk-container-id-56 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-56 div.sk-item::before, #sk-container-id-56 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-56 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-56 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-56 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-56 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-56 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-56 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-56 div.sk-label-container {text-align: center;}#sk-container-id-56 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-56 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-56\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor(learning_rate=0.01, max_depth=10, n_estimators=1000,\n",
       "                          random_state=42, subsample=0.5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-89\" type=\"checkbox\" checked><label for=\"sk-estimator-id-89\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(learning_rate=0.01, max_depth=10, n_estimators=1000,\n",
       "                          random_state=42, subsample=0.5)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingRegressor(learning_rate=0.01, max_depth=10, n_estimators=1000,\n",
       "                          random_state=42, subsample=0.5)"
      ]
     },
     "execution_count": 862,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-57 {color: black;}#sk-container-id-57 pre{padding: 0;}#sk-container-id-57 div.sk-toggleable {background-color: white;}#sk-container-id-57 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-57 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-57 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-57 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-57 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-57 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-57 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-57 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-57 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-57 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-57 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-57 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-57 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-57 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-57 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-57 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-57 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-57 div.sk-item {position: relative;z-index: 1;}#sk-container-id-57 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-57 div.sk-item::before, #sk-container-id-57 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-57 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-57 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-57 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-57 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-57 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-57 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-57 div.sk-label-container {text-align: center;}#sk-container-id-57 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-57 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-57\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RFECV(cv=KFold(n_splits=5, random_state=42, shuffle=True),\n",
       "      estimator=GradientBoostingRegressor(learning_rate=0.01, max_depth=10,\n",
       "                                          n_estimators=1000, random_state=42,\n",
       "                                          subsample=0.5),\n",
       "      scoring=&#x27;r2&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-90\" type=\"checkbox\" ><label for=\"sk-estimator-id-90\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RFECV</label><div class=\"sk-toggleable__content\"><pre>RFECV(cv=KFold(n_splits=5, random_state=42, shuffle=True),\n",
       "      estimator=GradientBoostingRegressor(learning_rate=0.01, max_depth=10,\n",
       "                                          n_estimators=1000, random_state=42,\n",
       "                                          subsample=0.5),\n",
       "      scoring=&#x27;r2&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-91\" type=\"checkbox\" ><label for=\"sk-estimator-id-91\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(learning_rate=0.01, max_depth=10, n_estimators=1000,\n",
       "                          random_state=42, subsample=0.5)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-92\" type=\"checkbox\" ><label for=\"sk-estimator-id-92\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(learning_rate=0.01, max_depth=10, n_estimators=1000,\n",
       "                          random_state=42, subsample=0.5)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RFECV(cv=KFold(n_splits=5, random_state=42, shuffle=True),\n",
       "      estimator=GradientBoostingRegressor(learning_rate=0.01, max_depth=10,\n",
       "                                          n_estimators=1000, random_state=42,\n",
       "                                          subsample=0.5),\n",
       "      scoring='r2')"
      ]
     },
     "execution_count": 863,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfecv = RFECV(estimator=estimator, cv=cv, scoring='r2')\n",
    "rfecv.fit(reduced_df_cor, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal number of features: 191\n"
     ]
    }
   ],
   "source": [
    "plt.plot(range(1, len(rfecv.cv_results_[\"mean_test_score\"]) + 1), rfecv.cv_results_[\"mean_test_score\"], color='#303F9F', linewidth=3)\n",
    "plt.xlabel(\"Number of Selected Features\")\n",
    "plt.ylabel(\"CV Score\")\n",
    "plt.title(\"Recursive Feature Elimination (RFE)\")\n",
    "plt.show()\n",
    "print(\"The optimal number of features: {}\".format(rfecv.n_features_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a new DataFrame called \"X_rfe\" that contains selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_df_cor = np.array(reduced_df_cor, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rfe = reduced_df_cor[:, rfecv.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1400, 191)"
      ]
     },
     "execution_count": 870,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_rfe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-58 {color: black;}#sk-container-id-58 pre{padding: 0;}#sk-container-id-58 div.sk-toggleable {background-color: white;}#sk-container-id-58 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-58 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-58 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-58 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-58 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-58 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-58 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-58 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-58 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-58 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-58 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-58 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-58 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-58 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-58 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-58 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-58 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-58 div.sk-item {position: relative;z-index: 1;}#sk-container-id-58 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-58 div.sk-item::before, #sk-container-id-58 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-58 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-58 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-58 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-58 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-58 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-58 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-58 div.sk-label-container {text-align: center;}#sk-container-id-58 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-58 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-58\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor(learning_rate=0.01, max_depth=10, n_estimators=1000,\n",
       "                          random_state=42, subsample=0.5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-93\" type=\"checkbox\" checked><label for=\"sk-estimator-id-93\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(learning_rate=0.01, max_depth=10, n_estimators=1000,\n",
       "                          random_state=42, subsample=0.5)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingRegressor(learning_rate=0.01, max_depth=10, n_estimators=1000,\n",
       "                          random_state=42, subsample=0.5)"
      ]
     },
     "execution_count": 871,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.fit(X_rfe, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_CV_GBR = cross_val_predict(estimator, X_rfe, y_tr, cv=cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 873,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q2_CV = round(r2_score(y_tr, y_pred_CV_GBR), 2)\n",
    "Q2_CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67"
      ]
     },
     "execution_count": 874,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE_CV=round(np.sqrt(mean_squared_error(y_tr, y_pred_CV_GBR)), 2)\n",
    "RMSE_CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 878,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Bit_1', 'Bit_4', 'Bit_8', 'Bit_15', 'Bit_25', 'Bit_31', 'Bit_33',\n",
       "       'Bit_36', 'Bit_41', 'Bit_42',\n",
       "       ...\n",
       "       'Bit_961', 'Bit_967', 'Bit_980', 'Bit_997', 'Bit_999', 'Bit_1009',\n",
       "       'Bit_1010', 'Bit_1016', 'Bit_1017', 'Bit_1019'],\n",
       "      dtype='object', length=191)"
      ]
     },
     "execution_count": 878,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_idx = rfecv.get_support()\n",
    "feature_name_rfecv = reduced_df_cor.columns[feature_idx]\n",
    "feature_name_rfecv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction for test set's molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 879,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ts=desc_ts[feature_name_rfecv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ts = np.array(y_ts, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 881,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_GBR = estimator.predict(x_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 882,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71"
      ]
     },
     "execution_count": 882,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q2_TS = round(r2_score(y_ts, y_pred_GBR), 2)\n",
    "Q2_TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66"
      ]
     },
     "execution_count": 883,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE_TS=round(np.sqrt(mean_squared_error(y_ts, y_pred_GBR)), 2)\n",
    "RMSE_TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Feature Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=2)]: Done 205 out of 205 | elapsed:  5.7min finished\n",
      "\n",
      "[2024-11-13 05:43:41] Features: 1/50 -- score: 0.18139096121440157[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:   59.1s\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=2)]: Done 204 out of 204 | elapsed:  5.3min finished\n",
      "\n",
      "[2024-11-13 05:49:02] Features: 2/50 -- score: 0.23409518291391765[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=2)]: Done 203 out of 203 | elapsed:  5.9min finished\n",
      "\n",
      "[2024-11-13 05:54:55] Features: 3/50 -- score: 0.264593635832376[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=2)]: Done 202 out of 202 | elapsed:  6.7min finished\n",
      "\n",
      "[2024-11-13 06:01:36] Features: 4/50 -- score: 0.30759258537652323[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=2)]: Done 201 out of 201 | elapsed: 11.6min finished\n",
      "\n",
      "[2024-11-13 06:13:13] Features: 5/50 -- score: 0.34280826597649394[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed: 10.5min\n",
      "[Parallel(n_jobs=2)]: Done 200 out of 200 | elapsed: 12.0min finished\n",
      "\n",
      "[2024-11-13 06:25:13] Features: 6/50 -- score: 0.3755984260528159[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=2)]: Done 199 out of 199 | elapsed:  8.0min finished\n",
      "\n",
      "[2024-11-13 06:33:16] Features: 7/50 -- score: 0.408374589447988[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=2)]: Done 198 out of 198 | elapsed:  9.0min finished\n",
      "\n",
      "[2024-11-13 06:42:14] Features: 8/50 -- score: 0.43096293345018644[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=2)]: Done 197 out of 197 | elapsed:  9.6min finished\n",
      "\n",
      "[2024-11-13 06:51:49] Features: 9/50 -- score: 0.45319073453452463[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=2)]: Done 196 out of 196 | elapsed: 10.5min finished\n",
      "\n",
      "[2024-11-13 07:02:20] Features: 10/50 -- score: 0.4731047922614442[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed: 10.7min\n",
      "[Parallel(n_jobs=2)]: Done 195 out of 195 | elapsed: 13.1min finished\n",
      "\n",
      "[2024-11-13 07:15:29] Features: 11/50 -- score: 0.4882796393793102[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed: 11.7min\n",
      "[Parallel(n_jobs=2)]: Done 194 out of 194 | elapsed: 14.4min finished\n",
      "\n",
      "[2024-11-13 07:29:53] Features: 12/50 -- score: 0.5026653960135776[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed: 14.8min\n",
      "[Parallel(n_jobs=2)]: Done 193 out of 193 | elapsed: 18.3min finished\n",
      "\n",
      "[2024-11-13 07:48:12] Features: 13/50 -- score: 0.5142757549516482[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed: 15.7min\n",
      "[Parallel(n_jobs=2)]: Done 192 out of 192 | elapsed: 19.1min finished\n",
      "\n",
      "[2024-11-13 08:07:19] Features: 14/50 -- score: 0.5261853525723914[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed: 34.0min\n",
      "[Parallel(n_jobs=2)]: Done 191 out of 191 | elapsed: 46.2min finished\n",
      "\n",
      "[2024-11-13 08:53:30] Features: 15/50 -- score: 0.5403558132932813[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed: 16.2min\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed: 60.5min\n",
      "[Parallel(n_jobs=2)]: Done 190 out of 190 | elapsed: 64.9min finished\n",
      "\n",
      "[2024-11-13 09:58:25] Features: 16/50 -- score: 0.5547126345727907[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed: 17.4min\n",
      "[Parallel(n_jobs=2)]: Done 189 out of 189 | elapsed: 20.6min finished\n",
      "\n",
      "[2024-11-13 10:19:05] Features: 17/50 -- score: 0.5677245787407907[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed: 17.1min\n",
      "[Parallel(n_jobs=2)]: Done 188 out of 188 | elapsed: 20.3min finished\n",
      "\n",
      "[2024-11-13 10:39:24] Features: 18/50 -- score: 0.5760010367348911[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed: 19.2min\n",
      "[Parallel(n_jobs=2)]: Done 187 out of 187 | elapsed: 22.8min finished\n",
      "\n",
      "[2024-11-13 11:02:13] Features: 19/50 -- score: 0.5866652174198993[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed: 19.7min\n",
      "[Parallel(n_jobs=2)]: Done 186 out of 186 | elapsed: 23.2min finished\n",
      "\n",
      "[2024-11-13 11:25:26] Features: 20/50 -- score: 0.5977103847310087[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed: 21.0min\n",
      "[Parallel(n_jobs=2)]: Done 185 out of 185 | elapsed: 24.7min finished\n",
      "\n",
      "[2024-11-13 11:50:05] Features: 21/50 -- score: 0.6084903813732658[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed: 21.9min\n",
      "[Parallel(n_jobs=2)]: Done 184 out of 184 | elapsed: 25.2min finished\n",
      "\n",
      "[2024-11-13 12:15:18] Features: 22/50 -- score: 0.6147963715697031[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  8.6min\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed: 28.2min\n",
      "[Parallel(n_jobs=2)]: Done 183 out of 183 | elapsed: 33.7min finished\n",
      "\n",
      "[2024-11-13 12:49:00] Features: 23/50 -- score: 0.6205130657928597[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed: 20.9min\n",
      "[Parallel(n_jobs=2)]: Done 182 out of 182 | elapsed: 24.0min finished\n",
      "\n",
      "[2024-11-13 13:13:00] Features: 24/50 -- score: 0.6271715781414836[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed: 21.8min\n",
      "[Parallel(n_jobs=2)]: Done 181 out of 181 | elapsed: 25.0min finished\n",
      "\n",
      "[2024-11-13 13:37:59] Features: 25/50 -- score: 0.6347543635731141[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed: 25.8min\n",
      "[Parallel(n_jobs=2)]: Done 180 out of 180 | elapsed: 28.8min finished\n",
      "\n",
      "[2024-11-13 14:06:47] Features: 26/50 -- score: 0.6405045584860112[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed: 22.2min\n",
      "[Parallel(n_jobs=2)]: Done 179 out of 179 | elapsed: 25.2min finished\n",
      "\n",
      "[2024-11-13 14:32:00] Features: 27/50 -- score: 0.6425012282445397[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed: 22.3min\n",
      "[Parallel(n_jobs=2)]: Done 178 out of 178 | elapsed: 25.1min finished\n",
      "\n",
      "[2024-11-13 14:57:07] Features: 28/50 -- score: 0.6465002123934466[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed: 23.6min\n",
      "[Parallel(n_jobs=2)]: Done 177 out of 177 | elapsed: 26.2min finished\n",
      "\n",
      "[2024-11-13 15:23:19] Features: 29/50 -- score: 0.6516156092574361[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed: 27.9min\n",
      "[Parallel(n_jobs=2)]: Done 176 out of 176 | elapsed: 30.8min finished\n",
      "\n",
      "[2024-11-13 15:54:07] Features: 30/50 -- score: 0.6630675775807837[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed: 25.9min\n",
      "[Parallel(n_jobs=2)]: Done 175 out of 175 | elapsed: 28.7min finished\n",
      "\n",
      "[2024-11-13 16:22:52] Features: 31/50 -- score: 0.6678605091642218[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed: 26.1min\n",
      "[Parallel(n_jobs=2)]: Done 174 out of 174 | elapsed: 28.6min finished\n",
      "\n",
      "[2024-11-13 16:51:31] Features: 32/50 -- score: 0.6733575158699144[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed: 26.5min\n",
      "[Parallel(n_jobs=2)]: Done 173 out of 173 | elapsed: 29.1min finished\n",
      "\n",
      "[2024-11-13 17:20:35] Features: 33/50 -- score: 0.6775078754335546[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed: 26.9min\n",
      "[Parallel(n_jobs=2)]: Done 172 out of 172 | elapsed: 29.2min finished\n",
      "\n",
      "[2024-11-13 17:49:49] Features: 34/50 -- score: 0.6802604520828373[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed: 27.0min\n",
      "[Parallel(n_jobs=2)]: Done 171 out of 171 | elapsed: 29.2min finished\n",
      "\n",
      "[2024-11-13 18:19:04] Features: 35/50 -- score: 0.6844079279267434[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed: 28.6min\n",
      "[Parallel(n_jobs=2)]: Done 170 out of 170 | elapsed: 30.8min finished\n",
      "\n",
      "[2024-11-13 18:49:52] Features: 36/50 -- score: 0.6891886413376535[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed: 28.5min\n",
      "[Parallel(n_jobs=2)]: Done 169 out of 169 | elapsed: 30.5min finished\n",
      "\n",
      "[2024-11-13 19:20:24] Features: 37/50 -- score: 0.6940573388839786[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed: 29.1min\n",
      "[Parallel(n_jobs=2)]: Done 168 out of 168 | elapsed: 30.9min finished\n",
      "\n",
      "[2024-11-13 19:51:18] Features: 38/50 -- score: 0.6969092779921412[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed: 30.4min\n",
      "[Parallel(n_jobs=2)]: Done 167 out of 167 | elapsed: 32.2min finished\n",
      "\n",
      "[2024-11-13 20:23:31] Features: 39/50 -- score: 0.701458448246173[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed: 31.2min\n",
      "[Parallel(n_jobs=2)]: Done 166 out of 166 | elapsed: 32.8min finished\n",
      "\n",
      "[2024-11-13 20:56:16] Features: 40/50 -- score: 0.7017502389668714[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed: 31.4min\n",
      "[Parallel(n_jobs=2)]: Done 165 out of 165 | elapsed: 32.9min finished\n",
      "\n",
      "[2024-11-13 21:29:10] Features: 41/50 -- score: 0.7037386323988327[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed: 34.6min\n",
      "[Parallel(n_jobs=2)]: Done 164 out of 164 | elapsed: 35.9min finished\n",
      "\n",
      "[2024-11-13 22:05:03] Features: 42/50 -- score: 0.7081617934948137[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed: 32.9min\n",
      "[Parallel(n_jobs=2)]: Done 163 out of 163 | elapsed: 34.0min finished\n",
      "\n",
      "[2024-11-13 22:39:05] Features: 43/50 -- score: 0.7117172349983992[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed: 32.4min\n",
      "[Parallel(n_jobs=2)]: Done 162 out of 162 | elapsed: 33.2min finished\n",
      "\n",
      "[2024-11-13 23:12:17] Features: 44/50 -- score: 0.7140037290174002[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed: 33.2min\n",
      "[Parallel(n_jobs=2)]: Done 161 out of 161 | elapsed: 33.8min finished\n",
      "\n",
      "[2024-11-13 23:46:06] Features: 45/50 -- score: 0.7150844808886873[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  8.1min\n",
      "[Parallel(n_jobs=2)]: Done 160 out of 160 | elapsed: 33.9min finished\n",
      "\n",
      "[2024-11-14 00:20:02] Features: 46/50 -- score: 0.717035973124947[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  8.2min\n",
      "[Parallel(n_jobs=2)]: Done 159 out of 159 | elapsed: 34.3min finished\n",
      "\n",
      "[2024-11-14 00:54:21] Features: 47/50 -- score: 0.7198196925840697[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  8.2min\n",
      "[Parallel(n_jobs=2)]: Done 158 out of 158 | elapsed: 34.2min finished\n",
      "\n",
      "[2024-11-14 01:28:33] Features: 48/50 -- score: 0.7214208481465976[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  8.6min\n",
      "[Parallel(n_jobs=2)]: Done 157 out of 157 | elapsed: 35.2min finished\n",
      "\n",
      "[2024-11-14 02:03:46] Features: 49/50 -- score: 0.7216991477797199[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=2)]: Done 156 out of 156 | elapsed: 34.5min finished\n",
      "\n",
      "[2024-11-14 02:38:14] Features: 50/50 -- score: 0.7228877720627404"
     ]
    }
   ],
   "source": [
    "sfs = SFS(estimator, \n",
    "           k_features=50, \n",
    "           forward=True, \n",
    "           floating=False, \n",
    "           verbose=2,\n",
    "           scoring='r2',\n",
    "           n_jobs=2,\n",
    "           cv=cv)\n",
    "\n",
    "\n",
    "sfs = sfs.fit(reduced_df_cor, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sfs = sfs.transform(reduced_df_cor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sfs = sfs.transform(desc_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor(learning_rate=0.01, max_depth=10, n_estimators=1000,\n",
       "                          random_state=42, subsample=0.5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(learning_rate=0.01, max_depth=10, n_estimators=1000,\n",
       "                          random_state=42, subsample=0.5)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingRegressor(learning_rate=0.01, max_depth=10, n_estimators=1000,\n",
       "                          random_state=42, subsample=0.5)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.fit(X_train_sfs, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_CV_GBR = cross_val_predict(estimator, X_train_sfs, y_tr, cv=cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q2_CV = round(r2_score(y_tr, y_pred_CV_GBR), 2)\n",
    "Q2_CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE_CV=round(np.sqrt(mean_squared_error(y_tr, y_pred_CV_GBR)), 2)\n",
    "RMSE_CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(351, 50)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_sfs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction for test set's molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ts = estimator.predict(X_test_sfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.83"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q2_TS = round(r2_score(y_ts, y_pred_ts), 2)\n",
    "Q2_TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.66"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE_TS=round(np.sqrt(mean_squared_error(y_ts, y_pred_ts)), 2)\n",
    "RMSE_TS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (rdkit)",
   "language": "python",
   "name": "my-rdkit-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
